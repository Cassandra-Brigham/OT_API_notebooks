{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b88ada4",
   "metadata": {},
   "source": [
    "# API access of the OpenTopography catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf5808b",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "## Authors\n",
    "Cassandra Brigham<sup>1,2</sup>\n",
    "\n",
    "<sup>1</sup>Arizona State University <sup>2</sup>OpenTopography\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* [1. Purpose](#1-purpose)  \n",
    "* [2. Setup](#2-setup)  \n",
    "    * [2.1. API Key](#21-api-key)  \n",
    "    * [2.2. Installation Options](#22-installation-options)  \n",
    "        * [2.2.1. Option 1: Install and run on Google Colaboratory](#221-option-1-install-and-run-on-google-colaboratory)  \n",
    "        * [2.2.2. Option 2: Download this notebook and run locally](#222-option-2-download-this-notebook-and-run-locally)  \n",
    "    * [2.3. Library Imports](#23-library-imports)  \n",
    "    * [2.4. Define Functions](#24-define-functions)  \n",
    "* [3. Data Access and Processing](#3-data-access-and-processing)  \n",
    "    * [3.1. Define Area of Interest](#31-define-area-of-interest)  \n",
    "        * [3.1.1. Option 1: Draw a bounding box on an interactive map](#311-option-1-draw-a-bounding-box-on-an-interactive-map)  \n",
    "        * [3.1.2. Option 2: Define bounds manually](#312-option-2-define-bounds-manually)  \n",
    "        * [3.1.3. Option 3: Define bounds using an uploaded shapefile](#313-option-3-define-bounds-using-an-uploaded-shapefile)  \n",
    "    * [3.2. Use OT catalog to find datasets](#32-use-ot-catalog-to-find-datasets)  \n",
    "* [4. Conclusions](#4-conclusions)  \n",
    "* [5. Resources](#5-resources)  \n",
    "* [6. Funding, Keywords, and Citation](#6-funding-keywords-and-citation)\n",
    "\n",
    "## 1. Purpose\n",
    "\n",
    "OpenTopography (OT) is a National Science Foundation–funded cyberinfrastructure facility hosted at the San Diego Supercomputer Center (SDSC) at UC San Diego in partnership with the EarthScope Consortium and Arizona State University. Its mission is to democratize online access to high-resolution topographic and bathymetric data acquired via lidar, radar, and photogrammetry, and to provide value‑added tools for data discovery, access, processing, and visualization in the cloud (opentopography.org).\n",
    "\n",
    "As a distributed facility, OpenTopography aggregates and federates datasets from multiple providers — including USGS 3DEP, NOAA coastal lidar, and Polar Geospatial Center’s ArcticDEM and REMA products — into a unified catalog. Data are accessible under open licenses, with professional training and guidance offered for effective use of the platform.\n",
    "\n",
    "To support programmatic workflows, OpenTopography offers <a href = \"https://portal.opentopography.org/apidocs/\"> a suite of RESTful web services documented in OpenAPI</a>, including:\n",
    "\n",
    "* <a href = \"\"> Global Datasets API </a> for global DEMs (SRTM, ALOS, NASADEM, Copernicus DSM, etc.)\n",
    "\n",
    "* <a href = \"\"> USGS 3DEP Raster API </a> for accessing 1 m, 10 m, and 30 m USGS DEM products\n",
    "\n",
    "* <a href = \"\"> <strong> Data Catalog API </strong> </a> (this notebook’s focus) for bounding‑box search of hosted and federated point cloud and raster datasets\n",
    "\n",
    "This and the other use-case specific Jupyter Notebooks developed as part of this effort for API use are available in a <a href=\"\"> Github repository </a> and may be run locally or on the <a href=\"\">Google Colaboratory</a> cloud platform.\n",
    "\n",
    "API access requires a free OT API key for academic users (rate limited to 500 calls/24 h for academic users) and supports JSON or XML output formats. Key access and management is available via the MyOpenTopo portal. For users who wish to integrate the OT API into commercial software or who need higher processing limits, information about Enterprise keys can be found <a href=\"https://opentopography.org/about/partner\">here</a>.\n",
    "\n",
    "By leveraging OpenTopography’s scalable, web‑service infrastructure, this notebook streamlines dataset discovery workflows and lays the groundwork for integrating OT data into PDAL/GDAL‑based geospatial pipelines.\n",
    "\n",
    "#### Specific features of this notebook\n",
    "\n",
    "1. Interactive AOI definition: Choose between manual coordinate entry, uploading a shapefile, or drawing a bounding box directly on an embedded ipyleaflet map.\n",
    "\n",
    "2. Automated OT Catalog queries: Build parameterized requests to the /otCatalog API endpoint, including WGS84 bounding boxes or WKT polygons, to fetch dataset metadata in JSON format. \n",
    "\n",
    "3. Result export: Save raw API responses to disk (results.json) for reproducibility and offline inspection.\n",
    "\n",
    "4. Metadata parsing and display: Extract key attributes (e.g., dataset name, bounds, acquisition date) from API results and present them in a clear, tabular summary.\n",
    "\n",
    "5. Modular code structure: Encapsulate query logic in functions to enable easy reuse and integration into larger PDAL/GDAL-based processing workflows.\n",
    "\n",
    "\n",
    "## 2. Setup\n",
    "\n",
    "### 2.1. API Key\n",
    "We recommend storing your OT API key in a environment variable. This prevents keys from being hardcoded in the source code, reducing the risk of exposure through sharing or version control. It also enhances flexibility, allowing the same code to be used in various environments without changes. Below are the steps to take to store your API key in an environment variable.  \n",
    "\n",
    "#### For Linux/macOS  \n",
    "\n",
    "Open up a Terminal window and find your shell's profile script. For Bash, you might find '~ /.bashrc' or '~ /.bash_profile'.\n",
    "For Zsh, you might find '~ /.zshrc'.  \n",
    "\n",
    "```cd ~```  \n",
    "```ls -a```  \n",
    "\n",
    "Once you know the name of your shell’s profile script, you can edit it using a text editor that operates in the terminal (like ```nano``` or ```vim```) or out side the terminal with the text editor of your choosing. This example will use '~/.zshrc' as the name of the shell profile script and ```nano``` as the text editor. If the file is read-only, you might need to use ```sudo``` to edit it.  \n",
    "\n",
    "```nano ~/.zshrc```  \n",
    "\n",
    "At the end of the .zshrc file, add a line to define your environment variable. 'your_api_key_here' is a stand in for the alphanumeric API key accessible at [MyOpenTopo](https://portal.opentopography.org/myopentopo) under \"Get an API Key.\"   \n",
    " \n",
    "```export OPENTOPOGRAPHY_API_KEY='your_api_key_here'```\n",
    "\n",
    "\n",
    "Exit (```control + X``` for ```nano```) and save (```Y``` to ```Save modified buffer (ANSWERING \"No\" WILL DESTROY CHANGES) ?``` then ```Enter``` for ```nano```).\n",
    "\n",
    "For your changes to take effect, you need to reload the .zshrc file or restart your terminal. To reload .zshrc without restarting, type the following command in your terminal and press Enter:  \n",
    "\n",
    "```source ~/.zshrc```  \n",
    "\n",
    "This will make the OPENTOPOGRAPHY_API_KEY environment variable available in all new terminal sessions.  \n",
    "\n",
    "#### For Windows  \n",
    "\n",
    "1. Search for \"Environment Variables\" in the Start menu.\n",
    "1. Click on \"Edit the system environment variables.\"\n",
    "1. In the System Properties window, click on \"Environment Variables.\"\n",
    "1. Click on \"New\" under System variables or User variables depending on your need.\n",
    "1. Set \"Variable name\" as OPENTOPOGRAPHY_API_KEY and \"Variable value\" as your actual API key. Your alphanumeric API key is accessible at [MyOpenTopo](https://portal.opentopography.org/myopentopo) under \"Get an API Key.\"\n",
    "1. Click OK and apply the changes.\n",
    "\n",
    "### 2.2. Installation Options\n",
    "There are two options for performing the workflow steps outlined below. **Option 1** is our suggested method for simplicity, as building a virtual environment with the required dependencies on the user's local file system can be challenging based on the user's experience level with Python and <a href=\"https://www.anaconda.com/\"> Anaconda</a>.\n",
    "\n",
    "1. **Option 1**: Launch the interactive Jupyter notebook on Google Colaboratory.\n",
    "    - Does not require creation of a virtual environment or installation on local file system.\n",
    "    - Requires Google account and access to personal Google Drive folder.\n",
    "    - Data download limits will be dependent on user's available Google Drive storage. \n",
    "    - If you wish to run this notebook in Google Colaboratory click the 'Open in Colab' badge below. \n",
    "    <br/><br/>\n",
    "2. **Option 2**: Download this Jupyter notebook (.ipynb file) to your local file system.\n",
    "    - Create a virtual conda environment containing the required dependencies.\n",
    "    - Run Juypter notebook on local machine.\n",
    "    - Data download limits and computation speed will be dependent on user's hardware.\n",
    "\n",
    "### 2.2.1. Option 1: Install and run on Google Colaboratory\n",
    "For ease-of-use, it is suggested to launch and execute these notebooks on <a href=\"https://colab.research.google.com/\">Google Colaboratory</a> (Colab, for short), Google's Cloud Platform. Dependencies will be installed on a virtual machine on Google's cloud servers and the code will be executed directly in your browser! A major benefit of this is that you will have direct access to Google's high-end CPU/GPUs and will not have to install any dependencies locally. All deliverables will be saved to your personal Google Drive. To experiment and run one of the below Jupyter Notebooks on Google Colab click the \"Open in Colab\" badge below.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cmspeed/OT_3DEP_Workflows/blob/main/notebooks/01_3DEP_Generate_DEM_User_AOI.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1b65c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell only excecutes if you're running on Colab. Installation process takes 2-3 minutes.\n",
    "import os, sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    \n",
    "  # Mount Google Drive. You will be prompted to grant file I/O access to Drive.\n",
    "  from google.colab import drive \n",
    "  drive.mount('/gdrive/') # Mount Google Drive! \n",
    "\n",
    "  # Clone OpenTopography 3DEP Workflow Git Repository\n",
    "  !git clone https://github.com/Cassandra-Brigham/OT_API_notebooks\n",
    "\n",
    "  #  Install the core dependencies (other than PDAL/GDAL) from requirements.txt\n",
    "  !pip install -r OT_API_notebooks/requirements.txt\n",
    "\n",
    "  # Install Conda (necessary to install PDAL/GDAL)\n",
    "  !pip install -q condacolab\n",
    "  import condacolab\n",
    "  condacolab.install()\n",
    "\n",
    "  #kernel will restart. Install PDAL and GDAL with Mamba.\n",
    "  !mamba install -q python-pdal gdal\n",
    "  \n",
    "  # Runtime will restart automatically. Do not rerun above cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8fdc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell only excecutes if you're running on Colab.\n",
    "import os, sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    # Colab requires proj_lib environment variable to be set manually.\n",
    "    os.environ['PROJ_LIB'] = '/usr/local/share/proj/'\n",
    "\n",
    "    !pip install python-dotenv  # if not already installed\n",
    "\n",
    "    from dotenv import set_key, find_dotenv\n",
    "\n",
    "    # 1) Locate (or create) your .env\n",
    "    #    find_dotenv returns the first .env in cwd hierarchy, or '' if none\n",
    "    env_path = find_dotenv(usecwd=True)\n",
    "    if not env_path:\n",
    "        env_path = \".env\"\n",
    "        open(env_path, \"a\").close()\n",
    "\n",
    "    # 2) Define your variables\n",
    "    variables = {\n",
    "        \"OPENTOPOGRAPHY_API_KEY\": os.getenv(\"OPENTOPOGRAPHY_API_KEY\", \"default_value\"),\n",
    "    }\n",
    "\n",
    "    # 3) Write/update each key in the .env\n",
    "    for key, val in variables.items():\n",
    "        set_key(env_path, key, val)\n",
    "\n",
    "    print(f\".env updated at {env_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ade7f4f",
   "metadata": {},
   "source": [
    "**If using Option 1 (Google Colab), proceed to Library Imports**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64976e0",
   "metadata": {},
   "source": [
    "<a id=\"222-option-2-download-this-notebook-and-run-locally\"></a>\n",
    "### 2.2.2. Option 2: Install and run on local file system\n",
    "\n",
    "If you would like to run the Jupyter Notebook on your local machine:\n",
    "\n",
    "Make a new directory on your local file system where the 3DEP Jupyter Notebooks (and all 3DEP data, if desired) will be saved. In this example case, the directory will be called `3DEP`.\n",
    "\n",
    "```bash  \n",
    "    mkdir OT_API\n",
    "```\n",
    "\n",
    "Change into the new directory and `git clone` the Github repository containing the Jupyter Notebooks and other relevant files to your local file system.\n",
    "\n",
    "```bash \n",
    "    cd OT_API\n",
    "    git clone https://github.com/\n",
    "```\n",
    "\n",
    "\n",
    "You will need to configure your Python environment using your preferred environment management system (e.g., Conda, virtualenv, pipenv). If you don’t already use one, we provide a helper script that:\n",
    "\n",
    "1. Detects your operating system  \n",
    "2. Installs Miniconda automatically on macOS or Linux(Windows users will need to install Miniconda manually following the instructions at https://docs.conda.io/en/latest/miniconda.html)\n",
    "\n",
    "First, make the installer executable and run it in your terminal:\n",
    "\n",
    "```bash\n",
    "    chmod +x install-miniconda.sh\n",
    "    ./install-miniconda.sh\n",
    "```\n",
    "\n",
    "Once Miniconda is installed (or if you already have Conda), create the environment from the provided `environment.yml`:\n",
    "\n",
    "```bash\n",
    "    conda env create -f environment.yml\n",
    "```\n",
    "\n",
    "After the environment is created, activate it and launch Jupyter Notebook:\n",
    "\n",
    "```bash\n",
    "    conda activate ot_env\n",
    "```\n",
    "\n",
    "Now, launch the chosen Jupyter Notebook. If unsure how to launch a Notebook, refer to this guide (https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/execute.html).\n",
    "\n",
    "**You may now proceed to Library Imports**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46c6c1",
   "metadata": {},
   "source": [
    "<a id=\"#23-library-imports\"></a>\n",
    "### 2.3. Library Imports\n",
    "\n",
    "After successfully completing the steps outlined in either **Option 1** or **Option 2**, we can now import the modules for use throughout the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eba3e234-9ae9-43f5-b3cd-611ad49ad397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from ipyleaflet import Map, DrawControl, basemaps, GeoJSON, LegendControl\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely import wkt\n",
    "from shapely.geometry import box, shape\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c8898c",
   "metadata": {},
   "source": [
    "<a id=\"#24-define-functions\"></a>\n",
    "### 2.4. Define Functions\n",
    "\n",
    "Several helper functions are provided in the cell below. These functions are necessary for successful execution of the remainder of the notebook. Broadly, they provide the utilities to:\n",
    "\n",
    "- draw an area of interest (AOI) on an interactive `ipyleaflet` map  \n",
    "- fetch and layer OpenTopography, USGS 3DEP, and NOAA boundary GeoJSON from GitHub  \n",
    "- capture and expose AOI extents (south, north, west, east) and a WKT polygon for downstream API queries  \n",
    "\n",
    "The primary function, `init_ot_catalog_map()`, encapsulates map initialization, draw‐control setup, boundary‐layer loading, and legend creation, and returns both the map object and a `bounds` dict with keys  \n",
    "```python\n",
    "{\n",
    "  'south': …,   # minimum latitude\n",
    "  'north': …,   # maximum latitude\n",
    "  'west':  …,   # minimum longitude\n",
    "  'east':  …,   # maximum longitude\n",
    "  'polygon': …  # WKT representation of the drawn rectangle\n",
    "}\n",
    "```\n",
    "\n",
    "**These functions can be modified as the user sees fit; however, they are designed to work with a simple execution of the below cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0238bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def geojson_to_wkt(geojson):\n",
    "    # Ensure the input is a Polygon\n",
    "    if geojson['type'] != 'Polygon':\n",
    "        raise ValueError(\"Input must be a Polygon\")\n",
    "\n",
    "    # Extract coordinates\n",
    "    coordinates = geojson['coordinates']\n",
    "    \n",
    "    # Convert coordinates to WKT string\n",
    "    wkt_coordinates = ', '.join(\n",
    "        f\"{', '.join(f'{x}, {y}' for x, y in polygon)}\"\n",
    "        for polygon in coordinates\n",
    "    )\n",
    "    \n",
    "    return wkt_coordinates\n",
    "\n",
    "def init_ot_catalog_map(\n",
    "    center=(39.8283, -98.5795),\n",
    "    zoom=3,\n",
    "    three_dep_url=\"https://raw.githubusercontent.com/OpenTopography/Data_Catalog_Spatial_Boundaries/main/usgs_3dep_boundaries.geojson\",\n",
    "    noaa_url=\"https://raw.githubusercontent.com/OpenTopography/Data_Catalog_Spatial_Boundaries/main/noaa_coastal_lidar_boundaries.geojson\",\n",
    "    ot_url=\"https://raw.githubusercontent.com/OpenTopography/Data_Catalog_Spatial_Boundaries/main/OT_PC_boundaries.geojson\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Initialize an ipyleaflet Map with:\n",
    "      - a DrawControl to capture an AOI bounding box (WKT + coords)\n",
    "      - 3DEP, NOAA, and OT dataset boundary layers\n",
    "      - a legend\n",
    "    \n",
    "    Returns:\n",
    "      m      -- the Map object\n",
    "      bounds -- dict with keys 'south', 'north', 'west', 'east', 'polygon'\n",
    "    \"\"\"\n",
    "    # storage for bounds\n",
    "    bounds = {'south': None, 'north': None, 'west': None, 'east': None, 'polygon': None}\n",
    "\n",
    "    # drawing callback\n",
    "    def _handle_draw(self, action, geo_json):\n",
    "        coords = geo_json['geometry']['coordinates'][0]\n",
    "        bounds['south'] = coords[0][1]\n",
    "        bounds['west']  = coords[0][0]\n",
    "        bounds['north'] = coords[2][1]\n",
    "        bounds['east']  = coords[2][0]\n",
    "        # convert GeoJSON to WKT\n",
    "        geom = shape(geo_json['geometry'])\n",
    "        bounds['polygon'] = geom.wkt\n",
    "        print(f\"Bounds updated: {bounds}\")\n",
    "\n",
    "    # create the map\n",
    "    m = Map(center=center, zoom=zoom, basemap=basemaps.Esri.WorldTopoMap)\n",
    "\n",
    "    # add drawing tool for rectangles only\n",
    "    draw_control = DrawControl(rectangle={'shapeOptions': {'color': '#fca45d'}})\n",
    "    draw_control.polyline = {}\n",
    "    draw_control.polygon = {}\n",
    "    draw_control.circle = {}\n",
    "    draw_control.circlemarker = {}\n",
    "    draw_control.on_draw(_handle_draw)\n",
    "    m.add_control(draw_control)\n",
    "\n",
    "    # helper to fetch & layer GeoJSON\n",
    "    def _add_layer(url, name, color):\n",
    "        resp = requests.get(url)\n",
    "        resp.raise_for_status()\n",
    "        gj = GeoJSON(data=resp.json(), name=name, style={'color': color})\n",
    "        m.add_layer(gj)\n",
    "\n",
    "    # add the three catalog layers\n",
    "    _add_layer(three_dep_url, \"3DEP datasets\", \"#228B22\")\n",
    "    _add_layer(noaa_url,     \"NOAA datasets\", \"#0000CD\")\n",
    "    _add_layer(ot_url,       \"OpenTopography datasets\", \"#fca45d\")\n",
    "\n",
    "    # legend\n",
    "    legend = LegendControl({\n",
    "        \"3DEP datasets\": \"#228B22\",\n",
    "        \"NOAA datasets\": \"#0000CD\",\n",
    "        \"OpenTopography datasets\": \"#fca45d\"\n",
    "    }, name=\"Legend\", position=\"topright\")\n",
    "    m.add_control(legend)\n",
    "\n",
    "    return m, bounds\n",
    "\n",
    "def define_bounds_manual(south: float, north: float, west: float, east: float) -> dict:\n",
    "    \"\"\"\n",
    "    Define an AOI by manually entering latitude/longitude bounds.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    south : float\n",
    "        Minimum latitude.\n",
    "    north : float\n",
    "        Maximum latitude.\n",
    "    west : float\n",
    "        Minimum longitude.\n",
    "    east : float\n",
    "        Maximum longitude.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with keys:\n",
    "          - 'south', 'north', 'west', 'east': the input bounds\n",
    "          - 'polygon': WKT of the rectangle defined by those bounds\n",
    "    \"\"\"\n",
    "    # create a rectangular polygon from the bounds\n",
    "    poly = box(west, south, east, north)\n",
    "    \n",
    "    # extract the bounds\n",
    "    bounds = {\n",
    "        'south': south,\n",
    "        'north': north,\n",
    "        'west':  west,\n",
    "        'east':  east,\n",
    "        'polygon': poly.wkt\n",
    "    }\n",
    "    return bounds\n",
    "\n",
    "def define_bounds_from_file(vector_path: str, target_crs: str = 'EPSG:4326') -> dict:\n",
    "    \"\"\"\n",
    "    Define an AOI by uploading a vector file (shapefile or GeoJSON), detect its CRS,\n",
    "    optionally reproject to a target CRS, and compute bounds.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vector_path : str\n",
    "        Path to a polygon vector file. Supported formats:\n",
    "        - Shapefile (.shp, with accompanying .shx/.dbf/etc.)\n",
    "        - GeoJSON (.geojson or .json)\n",
    "    target_crs : str, optional\n",
    "        The CRS to which geometries should be reprojected for bounds calculation\n",
    "        (default is 'EPSG:4326').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with keys:\n",
    "          - 'south', 'north', 'west', 'east': the bounding box of the file’s geometry\n",
    "            in the target CRS\n",
    "          - 'polygon': WKT of the full uploaded geometry (union of all features)\n",
    "            in the target CRS\n",
    "          - 'crs': the original CRS of the input file as a string\n",
    "    \"\"\"\n",
    "    # Read the file into a GeoDataFrame\n",
    "    gdf = gpd.read_file(vector_path)\n",
    "    if gdf.empty:\n",
    "        raise ValueError(f\"No geometries found in {vector_path!r}\")\n",
    "\n",
    "    # Detect the original CRS\n",
    "    original_crs = gdf.crs\n",
    "    if original_crs is None:\n",
    "        raise ValueError(f\"CRS is undefined for {vector_path!r}\")\n",
    "\n",
    "    # Reproject to the target CRS if necessary\n",
    "    if original_crs.to_string() != target_crs:\n",
    "        gdf = gdf.to_crs(target_crs)\n",
    "\n",
    "    # Merge all geometries into one\n",
    "    geom_union = gdf.geometry.union_all()\n",
    "    \n",
    "    # Extract the bounding box\n",
    "    minx_u, miny_u, maxx_u, maxy_u = geom_union.bounds\n",
    "    \n",
    "    # If the union is a MultiPolygon, replace it with its bounding‐box polygon\n",
    "    if geom_union.geom_type == \"MultiPolygon\":\n",
    "        geom_union = box(minx_u, miny_u, maxx_u, maxy_u)\n",
    "\n",
    "    return {\n",
    "        'south': miny_u,\n",
    "        'north': maxy_u,\n",
    "        'west': minx_u,\n",
    "        'east': maxx_u,\n",
    "        'polygon': geom_union.wkt,\n",
    "        'crs': original_crs.to_string()\n",
    "    }\n",
    "\n",
    "def fetch_ot_catalog(\n",
    "    base_url: str = \"https://portal.opentopography.org/API\",\n",
    "    endpoint: str = \"/otCatalog\",\n",
    "    bounds: dict = None,\n",
    "    polygon: str = None,\n",
    "    product_format: str = \"PointCloud\",\n",
    "    detail: bool = False,\n",
    "    output_format: str = \"json\",\n",
    "    include_federated: bool = True,\n",
    "    save_file: bool = True,\n",
    "    filename: str = None,\n",
    "    **request_kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Query the OpenTopography API and optionally save the results to a file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_url : str\n",
    "        The API base URL.\n",
    "    endpoint : str\n",
    "        The API endpoint (e.g. \"/otCatalog\").\n",
    "    bounds : dict, optional\n",
    "        A dict with keys 'west','south','east','north' specifying a WGS84 bbox.\n",
    "        Required if `polygon` is not provided.\n",
    "    polygon : str, optional\n",
    "        A WKT polygon string. If given, bbox (`bounds`) will be ignored.\n",
    "    product_format : str\n",
    "        Data product format: \"PointCloud\" or \"Raster\".\n",
    "    detail : bool\n",
    "        If True, request detailed metadata.\n",
    "    output_format : str\n",
    "        \"json\" (default) or \"xml\".\n",
    "    include_federated : bool\n",
    "        Whether to include federated datasets.\n",
    "    save_file : bool\n",
    "        If True, write the response to disk; otherwise return parsed data.\n",
    "    filename : str, optional\n",
    "        Filename to save to. If None, defaults to \"results.<output_format>\".\n",
    "    **request_kwargs\n",
    "        Additional keyword args passed to requests.get (e.g., headers, timeout).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict or bytes or None\n",
    "        If save_file is False, returns the parsed JSON (when output_format=\"json\")\n",
    "        or raw bytes (when output_format!=\"json\"). If save_file is True, returns None.\n",
    "    \"\"\"\n",
    "    # Build URL and params\n",
    "    url = base_url.rstrip(\"/\") + endpoint\n",
    "    params = {\n",
    "        \"productFormat\": product_format,\n",
    "        \"detail\": detail,\n",
    "        \"outputFormat\": output_format,\n",
    "        \"include_federated\": include_federated,\n",
    "    }\n",
    "\n",
    "    if polygon:\n",
    "        params[\"polygon\"] = polygon\n",
    "    elif bounds:\n",
    "        params.update({\n",
    "            \"minx\": bounds[\"west\"],\n",
    "            \"miny\": bounds[\"south\"],\n",
    "            \"maxx\": bounds[\"east\"],\n",
    "            \"maxy\": bounds[\"north\"],\n",
    "        })\n",
    "    else:\n",
    "        raise ValueError(\"Either `bounds` or `polygon` must be provided.\")\n",
    "\n",
    "    # Perform the request\n",
    "    response = requests.get(url, params=params, **request_kwargs)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Handle output\n",
    "    if save_file:\n",
    "        if filename is None:\n",
    "            filename = f\"results.{output_format}\"\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Saved output to {filename}\")\n",
    "        return None\n",
    "    else:\n",
    "        if output_format.lower() == \"json\":\n",
    "            return response.json()\n",
    "        else:\n",
    "            return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36db71ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_bounds_from_file(vector_path: str, target_crs: str = 'EPSG:4326') -> dict:\n",
    "    \"\"\"\n",
    "    Define an AOI by uploading a vector file (shapefile or GeoJSON), detect its CRS,\n",
    "    optionally reproject to a target CRS, and compute bounds.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vector_path : str\n",
    "        Path to a polygon vector file. Supported formats:\n",
    "        - Shapefile (.shp, with accompanying .shx/.dbf/etc.)\n",
    "        - GeoJSON (.geojson or .json)\n",
    "    target_crs : str, optional\n",
    "        The CRS to which geometries should be reprojected for bounds calculation\n",
    "        (default is 'EPSG:4326').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with keys:\n",
    "          - 'south', 'north', 'west', 'east': the bounding box of the file’s geometry\n",
    "            in the target CRS\n",
    "          - 'polygon': WKT of the full uploaded geometry (union of all features)\n",
    "            in the target CRS\n",
    "          - 'crs': the original CRS of the input file as a string\n",
    "    \"\"\"\n",
    "    # Read the file into a GeoDataFrame\n",
    "    gdf = gpd.read_file(vector_path)\n",
    "    if gdf.empty:\n",
    "        raise ValueError(f\"No geometries found in {vector_path!r}\")\n",
    "\n",
    "    # Detect the original CRS\n",
    "    original_crs = gdf.crs\n",
    "    if original_crs is None:\n",
    "        raise ValueError(f\"CRS is undefined for {vector_path!r}\")\n",
    "\n",
    "    # Reproject to the target CRS if necessary\n",
    "    if original_crs.to_string() != target_crs:\n",
    "        gdf = gdf.to_crs(target_crs)\n",
    "\n",
    "    # Merge all geometries into one\n",
    "    geom_union = gdf.geometry.union_all()\n",
    "    \n",
    "    # Extract the bounding box\n",
    "    minx_u, miny_u, maxx_u, maxy_u = geom_union.bounds\n",
    "    \n",
    "    # If the union is a MultiPolygon, replace it with its bounding‐box polygon\n",
    "    if geom_union.geom_type == \"MultiPolygon\":\n",
    "        geom_union = box(minx_u, miny_u, maxx_u, maxy_u)\n",
    "\n",
    "    return {\n",
    "        'south': miny_u,\n",
    "        'north': maxy_u,\n",
    "        'west': minx_u,\n",
    "        'east': maxx_u,\n",
    "        'polygon': geom_union.wkt,\n",
    "        'crs': original_crs.to_string()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e3b333",
   "metadata": {},
   "source": [
    "<a id=\"#3-data-access-and-processing\"></a>\n",
    "## 3. Data Access and Processing\n",
    "\n",
    "<a id=\"#31-define-area-of-interest\"></a>\n",
    "### 3.1. Define Area of Interest\n",
    "\n",
    "To specify the geographic region for your dataset search, you have three options. You can 1) manually enter latitude and longitude bounds if you know the exact coordinates of your area of interest; 2) upload a shapefile or GEOJSON to automatically populate the same extent variables; 3) draw a bounding box directly on the interactive map embedded in this notebook: simply click and drag to sketch the rectangle around your target area, and the notebook captures both the corner coordinates and the equivalent WKT polygon for your API queries.\n",
    "\n",
    "<a id=\"#311-option-1-draw-a-bounding-box-on-an-interactive-map\"></a>\n",
    "#### 3.1.1. Option 1: Draw a bounding box on an interactive map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09dbf08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1fc1297823541188f23c770d45a5106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[39.8283, -98.5795], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'z…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drawn bounds: {'south': None, 'north': None, 'west': None, 'east': None, 'polygon': None}\n"
     ]
    }
   ],
   "source": [
    "m, global_bounds = init_ot_catalog_map()\n",
    "display(m)\n",
    "print (\"Drawn bounds:\", global_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ed6111",
   "metadata": {},
   "source": [
    "<a id=\"#312-option-2-define-bounds-manually\"></a>\n",
    "#### 3.1.2. Option 2: Define bounds manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4d90dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual bounds: {'south': 34.0, 'north': 35.0, 'west': -118.5, 'east': -117.5, 'polygon': 'POLYGON ((-117.5 34, -117.5 35, -118.5 35, -118.5 34, -117.5 34))'}\n"
     ]
    }
   ],
   "source": [
    "global_bounds = define_bounds_manual(\n",
    "    south=34.0,\n",
    "    north=35.0,\n",
    "    west=-118.5,\n",
    "    east=-117.5\n",
    ")\n",
    "print(\"Manual bounds:\", global_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2368ba",
   "metadata": {},
   "source": [
    "<a id=\"#313-option-3-define-bounds-using-an-uploaded-shapefile\"></a>\n",
    "#### 3.1.3. Option 3: Define bounds using an uploaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6695d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File‐derived bounds: {'south': 39.812701501567226, 'north': 39.83787678884803, 'west': -85.67939879949874, 'east': -85.66006232462236, 'polygon': 'MULTIPOLYGON (((-85.66277575663145 39.82106676733368, -85.66305584356643 39.812701501567226, -85.67399998193764 39.81400961214544, -85.67138168483542 39.82134757286536, -85.66277575663145 39.82106676733368)), ((-85.66006232462236 39.83322432802182, -85.66654461406223 39.827477476275575, -85.67939879949874 39.833900886868406, -85.67708078211062 39.83787678884803, -85.66006232462236 39.83322432802182)))', 'crs': 'EPSG:32616'}\n"
     ]
    }
   ],
   "source": [
    "vector_path = \"test_shapefile.shp\"  # Replace with your file path \n",
    "global_bounds = define_bounds_from_file(vector_path)\n",
    "print(\"File‐derived bounds:\", bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170227dd",
   "metadata": {},
   "source": [
    "<a id=\"#32-use-ot-catalog-to-find-datasets\"></a>\n",
    "### 3.2. Use OT catalog to find datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c845700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output to results.json\n"
     ]
    }
   ],
   "source": [
    "data = fetch_ot_catalog(\n",
    "    bounds = global_bounds,\n",
    "    product_format =  \"PointCloud\",\n",
    "    detail = True,\n",
    "    output_format = \"json\",\n",
    "    include_federated = True,\n",
    "    save_file = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baec5e7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1216668390.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdata = = fetch_ot_catalog( fetch_ot_catalog(\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "data = fetch_ot_catalog(\n",
    "    polygon = global_bounds['polygon'],\n",
    "    product_format =  \"PointCloud\",\n",
    "    detail = True,\n",
    "    output_format = \"json\",\n",
    "    include_federated = True,\n",
    "    save_file = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e819c453",
   "metadata": {},
   "source": [
    "<a id=\"#4-conclusions\"></a>\n",
    "## 4. Conclusions\n",
    "\n",
    "<a id=\"#5-resources\"></a>\n",
    "## 5. Resources\n",
    "\n",
    "<a id=\"#6-funding-keywords-and-citation\"></a>\n",
    "## 6. Funding, Keywords, and Citation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8329af",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
